services:
  # Certbot service for automatic SSL certificate management
  certbot:
    image: certbot/certbot:latest
    volumes:
      - ../nginx/ssl:/etc/letsencrypt
      - ../nginx/certbot/www:/var/www/certbot
      - ../logs/certbot:/var/log/letsencrypt
    command: certonly --webroot --webroot-path=/var/www/certbot --email ${SSL_EMAIL} --agree-tos --no-eff-email --force-renewal -d ${DOMAIN_NAME}
    profiles:
      - ssl-setup
    depends_on:
      - nginx
    restart: "no"

  # Nginx reverse proxy - Production optimized
  nginx:
    image: nginx:alpine
    environment:
      - DOMAIN_NAME=${DOMAIN_NAME}
    ports:
      - "${NGINX_HTTP_PORT:-80}:80"
      - "${NGINX_HTTPS_PORT:-443}:443"
    volumes:
      - ../nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ../nginx/ssl:/etc/nginx/ssl:ro
      - ../nginx/ssl:/etc/letsencrypt:ro
      - ../nginx/certbot/www:/var/www/certbot:ro
      - ../logs/nginx:/var/log/nginx
      - ../nginx/conf.d/default.conf.template:/tmp/default.conf.template:ro
    depends_on:
      - workfolio
      - ai-backend
      - arachne
      - arachne-ui
    restart: unless-stopped
    networks:
      - portfolio-network-prod
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://127.0.0.1:80/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    command: >
      /bin/sh -c "sed 's/__DOMAIN_NAME__/'\"$DOMAIN_NAME\"'/g' /tmp/default.conf.template > /tmp/default.conf && nginx -g 'daemon off;'"
    deploy:
      resources:
        limits:
          memory: ${NGINX_MEMORY_LIMIT:-256M}
          cpus: "${NGINX_CPU_LIMIT:-0.5}"
        reservations:
          memory: 128M
          cpus: "0.25"

  # Workfolio - Production build
  workfolio:
    image: ${WORKFOLIO_IMAGE:-ghcr.io/your-username/personal-website/workfolio:latest}
    environment:
      - DOMAIN_NAME=${DOMAIN_NAME}
      - NODE_ENV=${WORKFOLIO_NODE_ENV:-production}
      - VITE_AI_BACKEND_URL=${VITE_AI_BACKEND_URL:-https://your-domain.com/api/ai}
    restart: unless-stopped
    networks:
      - portfolio-network-prod
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://127.0.0.1:80/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        limits:
          memory: ${WORKFOLIO_MEMORY_LIMIT:-512M}
          cpus: "${WORKFOLIO_CPU_LIMIT:-1.0}"
        reservations:
          memory: 256M
          cpus: "0.5"
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Arachne UI - Scraper console
  arachne-ui:
    image: ${ARACHNE_UI_IMAGE:-ghcr.io/your-username/personal-website/arachne-ui:latest}
    environment:
      - NODE_ENV=${ARACHNE_UI_NODE_ENV:-production}
      - PORT=${ARACHNE_UI_PORT:-3000}
      # Server-side URLs (can access Docker internal network)
      - AI_BACKEND_URL=${AI_BACKEND_URL:-http://ai-backend:3001}
      - ARACHNE_API_URL=${ARACHNE_API_URL:-http://arachne:8080}
      # Client-side URL (browser must go through nginx proxy)
      - NEXT_PUBLIC_ARACHNE_API_URL=/api/arachne
    depends_on:
      - ai-backend
      - arachne
    restart: unless-stopped
    networks:
      - portfolio-network-prod
    healthcheck:
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider http://127.0.0.1:3000/arachne/ || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        limits:
          memory: ${ARACHNE_UI_MEMORY_LIMIT:-512M}
          cpus: "${ARACHNE_UI_CPU_LIMIT:-1.0}"
        reservations:
          memory: 256M
          cpus: "0.5"
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # AI Backend - Production optimized
  ai-backend:
    image: ${AI_BACKEND_IMAGE:-ghcr.io/your-username/personal-website/ai-backend:latest}
    environment:
      - NODE_ENV=${AI_BACKEND_NODE_ENV:-production}
      - PORT=${AI_BACKEND_PORT:-3001}
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - LOG_LEVEL=${AI_BACKEND_LOG_LEVEL:-info}
      - ENABLE_METRICS=${AI_BACKEND_ENABLE_METRICS:-true}
      - RATE_LIMIT_WINDOW_MS=${AI_BACKEND_RATE_LIMIT_WINDOW_MS:-900000}
      - RATE_LIMIT_MAX_REQUESTS=${AI_BACKEND_RATE_LIMIT_MAX_REQUESTS:-100}
      - SESSION_TOKEN_SECRET=${SESSION_TOKEN_SECRET}
      - REDIS_URL=${AI_BACKEND_REDIS_URL:-redis://redis:6379/0}
      - TURNSTILE_SECRET=${TURNSTILE_SECRET}
      - TURNSTILE_REQUIRED=${TURNSTILE_REQUIRED:-false}
      - ARACHNE_URL=${ARACHNE_URL:-http://arachne:8080}
      - ARACHNE_API_TOKEN=${ARACHNE_API_TOKEN}
      - CORS_ALLOW_ORIGIN=${CORS_ALLOW_ORIGIN:-https://${DOMAIN_NAME}}
      - CORS_ALLOW_METHODS=${CORS_ALLOW_METHODS:-GET, POST, OPTIONS}
      - CORS_ALLOW_HEADERS=${CORS_ALLOW_HEADERS:-DNT,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Range,Authorization}
      - PROFILE_CONTEXT_PATH=/app/profile/profile.md
    restart: unless-stopped
    networks:
      - portfolio-network-prod
    healthcheck:
      test:
        [
          "CMD",
          "wget",
          "--no-verbose",
          "--tries=1",
          "--spider",
          "http://127.0.0.1:3001/health",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        limits:
          memory: ${AI_BACKEND_MEMORY_LIMIT:-1G}
          cpus: "${AI_BACKEND_CPU_LIMIT:-1.0}"
        reservations:
          memory: 512M
          cpus: "0.5"
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Arachne - Production optimized with enhanced settings
  arachne:
    image: ${ARACHNE_IMAGE:-ghcr.io/your-username/personal-website/arachne:latest}
    environment:
      - SCRAPER_REDIS_ADDR=${ARACHNE_REDIS_ADDR:-redis:6379}
      - SCRAPER_REDIS_DB=${ARACHNE_REDIS_DB:-0}
      - SCRAPER_ENABLE_METRICS=${ARACHNE_ENABLE_METRICS:-true}
      - SCRAPER_ENABLE_LOGGING=${ARACHNE_ENABLE_LOGGING:-true}
      - SCRAPER_LOG_LEVEL=${ARACHNE_LOG_LEVEL:-info}
      - SCRAPER_MAX_CONCURRENT=${ARACHNE_MAX_CONCURRENT:-10}
      - SCRAPER_REQUEST_TIMEOUT=${ARACHNE_REQUEST_TIMEOUT:-120s}
      - SCRAPER_TOTAL_TIMEOUT=${ARACHNE_TOTAL_TIMEOUT:-180s}
      - SCRAPER_USE_HEADLESS=${ARACHNE_USE_HEADLESS:-true}
      - SCRAPER_HEADLESS_IGNORE_CERT_ERRORS=${ARACHNE_HEADLESS_IGNORE_CERT_ERRORS:-false}
      - SCRAPER_HEADLESS_NO_SANDBOX=${ARACHNE_HEADLESS_NO_SANDBOX:-false}
      - SCRAPER_MAX_CONTENT_BYTES=${ARACHNE_MAX_CONTENT_BYTES:-400000}
      - SCRAPER_USER_AGENT=${ARACHNE_USER_AGENT:-Mozilla/5.0 (compatible; PortfolioBot/1.0)}
      - SCRAPER_RATE_LIMIT=${ARACHNE_RATE_LIMIT:-2}
      - SCRAPER_RATE_LIMIT_WINDOW=${ARACHNE_RATE_LIMIT_WINDOW:-1s}
      - SCRAPER_API_TOKEN=${ARACHNE_API_TOKEN}
    depends_on:
      - redis
    restart: unless-stopped
    networks:
      - portfolio-network-prod
    healthcheck:
      test:
        [
          "CMD",
          "wget",
          "--no-verbose",
          "--tries=1",
          "--spider",
          "http://127.0.0.1:8080/health",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        limits:
          memory: ${ARACHNE_MEMORY_LIMIT:-2G}
          cpus: "${ARACHNE_CPU_LIMIT:-1.0}"
        reservations:
          memory: 1G
          cpus: "0.5"
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Redis - Production optimized
  redis:
    image: redis:7-alpine
    volumes:
      - redis_data_prod:/data
      - ../logs/redis:/var/log/redis
    command: >
      redis-server 
      --appendonly yes 
      --maxmemory ${REDIS_MAX_MEMORY:-512mb} 
      --maxmemory-policy ${REDIS_MAX_MEMORY_POLICY:-allkeys-lru}
      --save 900 1
      --save 300 10
      --save 60 10000
    restart: unless-stopped
    networks:
      - portfolio-network-prod
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: ${REDIS_MEMORY_LIMIT:-1G}
          cpus: "${REDIS_CPU_LIMIT:-1.0}"
        reservations:
          memory: 512M
          cpus: "0.5"
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Redis Commander - Optional, can be disabled in production
  redis-commander:
    image: rediscommander/redis-commander:latest
    environment:
      - REDIS_HOSTS=local:redis:${REDIS_PORT:-6379}
    depends_on:
      - redis
    restart: unless-stopped
    networks:
      - ${DOCKER_NETWORK_NAME:-portfolio-network}-prod
    profiles:
      - monitoring
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: "0.5"
        reservations:
          memory: 128M
          cpus: "0.25"

networks:
  portfolio-network-prod:
    external: true
    name: portfolio-network-prod

volumes:
  redis_data_prod:
    driver: local
