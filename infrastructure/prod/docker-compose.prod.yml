services:
  # Certbot service for automatic SSL certificate management
  certbot:
    image: certbot/certbot:latest
    container_name: portfolio-certbot
    volumes:
      - ./nginx/ssl:/etc/letsencrypt
      - ./nginx/certbot/www:/var/www/certbot
      - ./logs/certbot:/var/log/letsencrypt
    command: certonly --webroot --webroot-path=/var/www/certbot --email ${SSL_EMAIL} --agree-tos --no-eff-email --force-renewal -d ${DOMAIN_NAME}
    profiles:
      - ssl-setup
    depends_on:
      - nginx
    restart: "no"

  # Nginx reverse proxy - Production optimized
  nginx:
    image: nginx:alpine
    container_name: portfolio-nginx-prod
    ports:
      - "${NGINX_HTTP_PORT:-80}:80"
      - "${NGINX_HTTPS_PORT:-443}:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/conf.d:/etc/nginx/conf.d:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
      - ./nginx/certbot/www:/var/www/certbot:ro
      - ./logs/nginx:/var/log/nginx
    depends_on:
      workfolio:
        condition: service_healthy
      ai-backend:
        condition: service_healthy
      arachne:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - ${DOCKER_NETWORK_NAME:-portfolio-network}-prod
    healthcheck:
      test:
        [
          "CMD",
          "wget",
          "--no-verbose",
          "--tries=1",
          "--spider",
          "http://localhost:80/health",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        limits:
          memory: ${NGINX_MEMORY_LIMIT:-256M}
          cpus: "${NGINX_CPU_LIMIT:-0.5}"
        reservations:
          memory: 128M
          cpus: "0.25"

  # Workfolio - Production build
  workfolio:
    build:
      context: ../workfolio
      dockerfile: Dockerfile
      args:
        NODE_ENV: production
    container_name: portfolio-workfolio-prod
    environment:
      - NODE_ENV=${WORKFOLIO_NODE_ENV:-production}
      - VITE_AI_BACKEND_URL=${VITE_AI_BACKEND_URL:-https://your-domain.com/api/ai}
    restart: unless-stopped
    networks:
      - ${DOCKER_NETWORK_NAME:-portfolio-network}-prod
    healthcheck:
      test:
        [
          "CMD",
          "wget",
          "--no-verbose",
          "--tries=1",
          "--spider",
          "http://localhost:3000",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        limits:
          memory: ${WORKFOLIO_MEMORY_LIMIT:-512M}
          cpus: "${WORKFOLIO_CPU_LIMIT:-1.0}"
        reservations:
          memory: 256M
          cpus: "0.5"
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # AI Backend - Production optimized
  ai-backend:
    build:
      context: ../services/ai-backend
      dockerfile: Dockerfile
      args:
        NODE_ENV: production
    container_name: portfolio-ai-backend-prod
    environment:
      - NODE_ENV=${AI_BACKEND_NODE_ENV:-production}
      - PORT=${AI_BACKEND_PORT:-3001}
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - LOG_LEVEL=${AI_BACKEND_LOG_LEVEL:-info}
      - ENABLE_METRICS=${AI_BACKEND_ENABLE_METRICS:-true}
      - RATE_LIMIT_WINDOW_MS=${AI_BACKEND_RATE_LIMIT_WINDOW_MS:-900000}
      - RATE_LIMIT_MAX_REQUESTS=${AI_BACKEND_RATE_LIMIT_MAX_REQUESTS:-100}
      - SESSION_TOKEN_SECRET=${SESSION_TOKEN_SECRET}
      - REDIS_URL=${AI_BACKEND_REDIS_URL:-redis://redis:6379/0}
      - TURNSTILE_SECRET=${TURNSTILE_SECRET}
    restart: unless-stopped
    networks:
      - ${DOCKER_NETWORK_NAME:-portfolio-network}-prod
    healthcheck:
      test:
        [
          "CMD",
          "wget",
          "--no-verbose",
          "--tries=1",
          "--spider",
          "http://localhost:3001/health",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        limits:
          memory: ${AI_BACKEND_MEMORY_LIMIT:-1G}
          cpus: "${AI_BACKEND_CPU_LIMIT:-1.0}"
        reservations:
          memory: 512M
          cpus: "0.5"
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Arachne - Production optimized with enhanced settings
  arachne:
    build:
      context: ../services/arachne
      dockerfile: Dockerfile
    container_name: portfolio-arachne-prod
    environment:
      - SCRAPER_REDIS_ADDR=${ARACHNE_REDIS_ADDR:-redis:6379}
      - SCRAPER_REDIS_DB=${ARACHNE_REDIS_DB:-0}
      - SCRAPER_ENABLE_METRICS=${ARACHNE_ENABLE_METRICS:-true}
      - SCRAPER_ENABLE_LOGGING=${ARACHNE_ENABLE_LOGGING:-true}
      - SCRAPER_LOG_LEVEL=${ARACHNE_LOG_LEVEL:-info}
      - SCRAPER_MAX_CONCURRENT=${ARACHNE_MAX_CONCURRENT:-10}
      - SCRAPER_REQUEST_TIMEOUT=${ARACHNE_REQUEST_TIMEOUT:-120s}
      - SCRAPER_TOTAL_TIMEOUT=${ARACHNE_TOTAL_TIMEOUT:-180s}
      - SCRAPER_USE_HEADLESS=${ARACHNE_USE_HEADLESS:-true}
      - SCRAPER_USER_AGENT=${ARACHNE_USER_AGENT:-Mozilla/5.0 (compatible; PortfolioBot/1.0)}
      - SCRAPER_RATE_LIMIT=${ARACHNE_RATE_LIMIT:-2}
      - SCRAPER_RATE_LIMIT_WINDOW=${ARACHNE_RATE_LIMIT_WINDOW:-1s}
    depends_on:
      redis:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - ${DOCKER_NETWORK_NAME:-portfolio-network}-prod
    healthcheck:
      test:
        [
          "CMD",
          "wget",
          "--no-verbose",
          "--tries=1",
          "--spider",
          "http://localhost:8080/health",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        limits:
          memory: ${ARACHNE_MEMORY_LIMIT:-2G}
          cpus: "${ARACHNE_CPU_LIMIT:-2.0}"
        reservations:
          memory: 1G
          cpus: "1.0"
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Redis - Production optimized
  redis:
    image: redis:7-alpine
    container_name: portfolio-redis-prod
    volumes:
      - redis_data_prod:/data
      - ./logs/redis:/var/log/redis
    command: >
      redis-server 
      --appendonly yes 
      --maxmemory ${REDIS_MAX_MEMORY:-512mb} 
      --maxmemory-policy ${REDIS_MAX_MEMORY_POLICY:-allkeys-lru}
      --save 900 1
      --save 300 10
      --save 60 10000
    restart: unless-stopped
    networks:
      - ${DOCKER_NETWORK_NAME:-portfolio-network}-prod
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: ${REDIS_MEMORY_LIMIT:-1G}
          cpus: "${REDIS_CPU_LIMIT:-1.0}"
        reservations:
          memory: 512M
          cpus: "0.5"
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Redis Commander - Optional, can be disabled in production
  redis-commander:
    image: rediscommander/redis-commander:latest
    container_name: portfolio-redis-commander-prod
    environment:
      - REDIS_HOSTS=local:redis:${REDIS_PORT:-6379}
    depends_on:
      - redis
    restart: unless-stopped
    networks:
      - ${DOCKER_NETWORK_NAME:-portfolio-network}-prod
    profiles:
      - monitoring
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: "0.5"
        reservations:
          memory: 128M
          cpus: "0.25"

networks:
  ${DOCKER_NETWORK_NAME:-portfolio-network}-prod:
    driver: bridge
    ipam:
      config:
        - subnet: ${DOCKER_NETWORK_SUBNET:-172.20.0.0/16}

volumes:
  redis_data_prod:
    driver: local
