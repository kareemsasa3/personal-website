name: SSH Deploy
description: Deploy to the production server over SSH with cleanup, network setup, and Docker Compose
inputs:
  host:
    description: Production host
    required: true
  user:
    description: SSH username
    required: true
  port:
    description: SSH port
    required: true
  ssh_key:
    description: SSH private key (ed25519)
    required: true
  ghcr_username:
    description: GHCR username
    required: true
  ghcr_token:
    description: GHCR token
    required: true
  repository:
    description: owner/repo for images
    required: true
  sha:
    description: Git SHA to deploy
    required: true
runs:
  using: composite
  steps:
    - name: Configure SSH
      shell: bash
      run: |
        mkdir -p ~/.ssh
        chmod 700 ~/.ssh
        # Support both raw OpenSSH key and base64-encoded key in secret
        KEY_RAW="${{ inputs.ssh_key }}"
        # Detect plaintext OpenSSH key; use -- to prevent grep from treating dashes as options
        if printf "%s" "$KEY_RAW" | grep -q -- "BEGIN OPENSSH PRIVATE KEY"; then
          # Looks like a PEM/OpenSSH key; normalize newlines
          printf "%s" "$KEY_RAW" | sed 's/\\n/\n/g' > ~/.ssh/id_ed25519
        else
          # Try base64 decode first; fallback to literal write if decode fails
          printf "%s" "$KEY_RAW" | tr -d '\r' | base64 -d > ~/.ssh/id_ed25519 2>/dev/null || true
          if ! grep -q -- "BEGIN OPENSSH PRIVATE KEY" ~/.ssh/id_ed25519 2>/dev/null; then
            printf "%s" "$KEY_RAW" | sed 's/\\n/\n/g' > ~/.ssh/id_ed25519
          fi
        fi
        chmod 600 ~/.ssh/id_ed25519
        # Quick validation/warning if the key is passphrase-protected or invalid
        if ! ssh-keygen -y -f ~/.ssh/id_ed25519 >/dev/null 2>&1; then
          echo "WARNING: SSH key appears invalid or passphrase-protected. Ensure an unencrypted OpenSSH ed25519 private key is provided in secrets." >&2
          echo "Key header (first line): $(head -n1 ~/.ssh/id_ed25519 2>/dev/null || echo 'N/A')" >&2
        fi
        # Best-effort host key prefetch; do not fail if host is unreachable
        ssh-keyscan -T 10 -p "${{ inputs.port }}" "${{ inputs.host }}" >> ~/.ssh/known_hosts 2>/dev/null || true

    - name: Sync deployment files to server
      shell: bash
      run: |
        HOST_RAW='${{ inputs.host }}'
        USER_RAW='${{ inputs.user }}'
        PORT_RAW='${{ inputs.port }}'
        HOST=$(printf "%s" "$HOST_RAW" | tr -d ' \t\r\n')
        USER=$(printf "%s" "$USER_RAW" | tr -d ' \t\r\n')
        PORT=$(printf "%s" "$PORT_RAW" | tr -d ' \t\r\n')
        if [ -z "$PORT" ]; then PORT=22; fi
        SSH_OPTS="-i ~/.ssh/id_ed25519 -o IdentitiesOnly=yes -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o ConnectTimeout=60 -o ConnectionAttempts=3 -o ServerAliveInterval=15 -o ServerAliveCountMax=4 -o PreferredAuthentications=publickey -o PubkeyAuthentication=yes -o IPQoS=none"
        echo "Syncing infrastructure/ to server..."
        tar -czf - infrastructure | ssh $SSH_OPTS -p "$PORT" "$USER@$HOST" "mkdir -p ~/personal-website && tar -xzf - -C ~/personal-website"

    - name: Deploy over SSH
      shell: bash
      run: |
        HOST_RAW='${{ inputs.host }}'
        USER_RAW='${{ inputs.user }}'
        PORT_RAW='${{ inputs.port }}'
        HOST=$(printf "%s" "$HOST_RAW" | tr -d ' \t\r\n')
        USER=$(printf "%s" "$USER_RAW" | tr -d ' \t\r\n')
        PORT=$(printf "%s" "$PORT_RAW" | tr -d ' \t\r\n')
        if [ -z "$PORT" ]; then PORT=22; fi

        echo "Resolving host: $HOST"
        (getent hosts "$HOST" || nslookup -timeout=5 "$HOST" || dig +short "$HOST") 2>/dev/null || true

        echo "Checking TCP connectivity to $HOST:$PORT"
        if command -v nc >/dev/null 2>&1; then
          nc -zv -w 10 "$HOST" "$PORT" || true
        else
          (echo > "/dev/tcp/$HOST/$PORT") >/dev/null 2>&1 || true
        fi

        # Prepare remote script once, then stream it to SSH (allows retries)
        cat > /tmp/remote_deploy.sh << 'RSCRIPT'
        set -e
        cd "$HOME/personal-website"

        echo "Disk usage before cleanup:" && df -h /
        echo "Docker disk usage before cleanup:" && docker system df || true
        docker container prune -f || true
        docker image prune -af || true
        docker builder prune -af || true
        docker network prune -f || true
        docker volume prune -f || true
        sudo find /var/lib/docker/containers -type f -name "*json.log" -size +100M -exec truncate -s 0 {} \; 2>/dev/null || true
        sudo journalctl --vacuum-size=100M 2>/dev/null || true

        DOCKER_CONFIG_DIR="$(mktemp -d -t docker-config-XXXXXX 2>/dev/null || echo /tmp/docker-config)"
        export DOCKER_CONFIG="$DOCKER_CONFIG_DIR"
        echo "${{ inputs.ghcr_token }}" | docker login ghcr.io -u "${{ inputs.ghcr_username }}" --password-stdin

        export WORKFOLIO_IMAGE=ghcr.io/${{ inputs.repository }}/workfolio:${{ inputs.sha }}
        export AI_BACKEND_IMAGE=ghcr.io/${{ inputs.repository }}/ai-backend:${{ inputs.sha }}
        export ARACHNE_IMAGE=ghcr.io/${{ inputs.repository }}/arachne:${{ inputs.sha }}

        echo "Pre-pulling images to ensure availability..."
        MISSING="0"
        docker pull "$WORKFOLIO_IMAGE" || MISSING="1"
        docker pull "$AI_BACKEND_IMAGE" || MISSING="1"
        docker pull "$ARACHNE_IMAGE" || MISSING="1"
        if [ "$MISSING" = "1" ]; then
          echo "ERROR: One or more images are missing in GHCR for SHA ${{ inputs.sha }}. Ensure the CI build-and-push job completed successfully." >&2
          exit 1
        fi

        if [ -f infrastructure/prod/.env ]; then
          echo "Loading environment from infrastructure/prod/.env"
          set -a; . infrastructure/prod/.env; set +a
        else
          echo "WARNING: infrastructure/prod/.env not found; continuing without extra env" >&2
        fi

        # If TLS certs are missing, obtain them via standalone certbot (binds to host :80)
        DOMAIN_NAME_VALUE=${DOMAIN_NAME:-kareemsasa.dev}
        SSL_EMAIL_VALUE=${SSL_EMAIL:-${USER}@localhost}
        CERT_PATH_HOST="$(pwd)/infrastructure/nginx/ssl/live/${DOMAIN_NAME_VALUE}/fullchain.pem"
        if [ ! -f "$CERT_PATH_HOST" ]; then
          echo "TLS certificates for ${DOMAIN_NAME_VALUE} not found. Attempting standalone certbot issuance..."
          # Ensure directories exist
          mkdir -p infrastructure/nginx/ssl
          mkdir -p infrastructure/nginx/certbot/www
          # Stop any service bound to :80 to free the port (best effort)
          (docker ps --format '{{.ID}} {{.Ports}} {{.Names}}' | grep -E ':80->|:80/' | awk '{print $1}' | xargs -r docker stop) || true
          # Run certbot in standalone mode to write into our ssl mount
          docker run --rm -p 80:80 \
            -v "$(pwd)/infrastructure/nginx/ssl:/etc/letsencrypt" \
            certbot/certbot:latest certonly --standalone \
            -d "$DOMAIN_NAME_VALUE" -m "$SSL_EMAIL_VALUE" \
            --agree-tos --no-eff-email --non-interactive --preferred-challenges http || {
              echo "ERROR: Certbot issuance failed. Check DNS A record points to this server and port 80 is reachable." >&2
              exit 1
            }
          echo "Certificate obtained for ${DOMAIN_NAME_VALUE}."
        else
          echo "Found existing TLS certificate at $CERT_PATH_HOST"
        fi

        # Ensure CPU limits are valid for the host (avoid errors on single-core hosts)
        HOST_CPUS=$( (command -v nproc >/dev/null 2>&1 && nproc) || sysctl -n hw.ncpu 2>/dev/null || echo 1 )
        if [ "$HOST_CPUS" -lt 2 ]; then
          echo "Detected $HOST_CPUS CPU(s) on host; capping ARACHNE_CPU_LIMIT to 1.0 to avoid compose CPU limit errors" >&2
          export ARACHNE_CPU_LIMIT="1.0"
        fi

        docker network create portfolio-network-prod >/dev/null 2>&1 || true
        # Override to force images (and null-out any build) so server never builds locally
        cat > /tmp/compose.images.override.yml << 'IMG'
        services:
          workfolio:
            build: null
            image: ${WORKFOLIO_IMAGE}
          ai-backend:
            build: null
            image: ${AI_BACKEND_IMAGE}
          arachne:
            build: null
            image: ${ARACHNE_IMAGE}
        IMG

        cat > /tmp/compose.network.override.yml << 'OVR'
        networks:
          portfolio-network-prod:
            external: true
            name: portfolio-network-prod
        OVR

        if command -v docker-compose >/dev/null 2>&1; then COMPOSE_CMD="docker-compose"; else COMPOSE_CMD="docker compose"; fi
        # Bring stack down with same overrides to prevent name conflicts and stale containers
        $COMPOSE_CMD -f infrastructure/docker-compose.yml -f infrastructure/prod/docker-compose.prod.yml -f /tmp/compose.images.override.yml -f /tmp/compose.network.override.yml down --remove-orphans || true
        # Extra safety: remove any lingering conflicting containers by explicit names
        docker rm -f portfolio-redis-prod portfolio-workfolio-prod portfolio-ai-backend-prod portfolio-arachne-prod >/dev/null 2>&1 || true
        # And remove any container matching portfolio-*-prod just in case
        CONFLICTING_CONTAINERS=$(docker ps -aq --filter name='^/portfolio-.*-prod$' || true)
        if [ -n "$CONFLICTING_CONTAINERS" ]; then
          echo "Removing lingering containers: $CONFLICTING_CONTAINERS"
          docker rm -f $CONFLICTING_CONTAINERS >/dev/null 2>&1 || true
        fi
        # Small wait to ensure Docker releases names
        sleep 2
        $COMPOSE_CMD -f infrastructure/docker-compose.yml -f infrastructure/prod/docker-compose.prod.yml -f /tmp/compose.images.override.yml -f /tmp/compose.network.override.yml pull || true
        $COMPOSE_CMD -f infrastructure/docker-compose.yml -f infrastructure/prod/docker-compose.prod.yml -f /tmp/compose.images.override.yml -f /tmp/compose.network.override.yml up -d --no-build --pull always
        $COMPOSE_CMD -f infrastructure/docker-compose.yml -f infrastructure/prod/docker-compose.prod.yml -f /tmp/compose.images.override.yml -f /tmp/compose.network.override.yml ps

        echo "Disk usage after cleanup:" && df -h /
        echo "Docker disk usage after cleanup:" && docker system df || true
        RSCRIPT

        SSH_OPTS="-i ~/.ssh/id_ed25519 -o IdentitiesOnly=yes -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o ConnectTimeout=60 -o ConnectionAttempts=3 -o ServerAliveInterval=15 -o ServerAliveCountMax=4 -o PreferredAuthentications=publickey -o PubkeyAuthentication=yes -o IPQoS=none"

        success=""
        for attempt in 1 2 3; do
          echo "SSH attempt $attempt..."
          if ssh -T $SSH_OPTS -p "$PORT" "$USER@$HOST" bash -s < /tmp/remote_deploy.sh; then
            success="yes"; break
          fi
          echo "SSH attempt $attempt failed. Retrying in 15s..."
          sleep 15
        done

        if [ -z "$success" ]; then
          echo "Final SSH attempt with verbose logging (-vvv) for diagnostics:" >&2
          echo "Printing remote SSH banner via netcat for diagnostics (if available)" >&2
          if command -v nc >/dev/null 2>&1; then
            nc -v -w 5 "$HOST" "$PORT" </dev/null || true
          fi
          ssh -vvv -T $SSH_OPTS -p "$PORT" "$USER@$HOST" bash -s < /tmp/remote_deploy.sh || true
          exit 1
        fi


